{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Price (€)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-04-28 00:00:00.000</td>\n",
       "      <td>103.186200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-04-29 00:00:00.000</td>\n",
       "      <td>110.374500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-04-30 00:00:00.000</td>\n",
       "      <td>106.312800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-05-01 00:00:00.000</td>\n",
       "      <td>88.629100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-05-02 00:00:00.000</td>\n",
       "      <td>80.592300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3957</th>\n",
       "      <td>2024-02-29 00:00:00.000</td>\n",
       "      <td>57717.736389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>2024-03-01 00:00:00.000</td>\n",
       "      <td>56734.564616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3959</th>\n",
       "      <td>2024-03-02 00:00:00.000</td>\n",
       "      <td>57560.483900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3960</th>\n",
       "      <td>2024-03-03 00:00:00.000</td>\n",
       "      <td>57229.676585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3961</th>\n",
       "      <td>2024-03-04 00:00:00.000</td>\n",
       "      <td>58157.094855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Timestamp     Price (€)\n",
       "0     2013-04-28 00:00:00.000    103.186200\n",
       "1     2013-04-29 00:00:00.000    110.374500\n",
       "2     2013-04-30 00:00:00.000    106.312800\n",
       "3     2013-05-01 00:00:00.000     88.629100\n",
       "4     2013-05-02 00:00:00.000     80.592300\n",
       "...                       ...           ...\n",
       "3957  2024-02-29 00:00:00.000  57717.736389\n",
       "3958  2024-03-01 00:00:00.000  56734.564616\n",
       "3959  2024-03-02 00:00:00.000  57560.483900\n",
       "3960  2024-03-03 00:00:00.000  57229.676585\n",
       "3961  2024-03-04 00:00:00.000  58157.094855\n",
       "\n",
       "[3962 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dati = pd.read_csv('bitcoin_data_28-4-2013_4-3-2024_granularità_1_giorno.csv')\n",
    "dati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri ottimizzati: [ 4.54751661e-03  1.92959282e+00  2.94437752e+01  9.97093830e-01\n",
      " -1.27923201e+01 -1.78820149e+03]\n",
      "MAE: 5359.841786647315\n",
      "MAPE: 234.73707941722188%\n",
      "Numero di valutazioni della funzione: 324\n"
     ]
    }
   ],
   "source": [
    "# Contatore globale\n",
    "eval_count = 0\n",
    "\n",
    "# Legge da fittare: y = A * x^B\n",
    "def legge(x, A, B, C, D, E, F):\n",
    "    global eval_count\n",
    "    eval_count += 1\n",
    "    return A * x**B + C * np.sin(D*x + E) + F\n",
    "\n",
    "# Creiamo un array per l'asse x (tempo o indice dei prezzi)\n",
    "x = np.arange(1, len(dati) + 1)\n",
    "y = dati['Price (€)'].values\n",
    "\n",
    "# Ottimizzazione dei parametri\n",
    "try:\n",
    "    # curve_fit cerca i migliori parametri A e B\n",
    "    popt, pcov = curve_fit(legge, x, y, p0=[1, 1, 1, 1, 1, 0], maxfev=10000)\n",
    "\n",
    "    # Generazione dei valori predetti\n",
    "    y_pred = legge(x, *popt)\n",
    "\n",
    "    # Calcolo degli errori\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
    "\n",
    "    print(f\"Parametri ottimizzati: {popt}\")\n",
    "    print(f\"MAE: {mae}\")\n",
    "    print(f\"MAPE: {mape}%\")\n",
    "    print(f\"Numero di valutazioni della funzione: {eval_count}\")\n",
    "\n",
    "except RuntimeError as e:\n",
    "    print(\"Errore nell'ottimizzazione:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.85425086e-06, -1.02818258e-04,  1.65466477e-04,\n",
       "        -1.07061874e-08,  9.25224685e-06, -4.44139248e-01],\n",
       "       [-1.02818258e-04,  2.74454381e-03, -4.28154896e-03,\n",
       "         2.97210657e-07, -2.64182649e-04,  1.16640543e+01],\n",
       "       [ 1.65466477e-04, -4.28154896e-03,  3.29326561e+04,\n",
       "         5.83516071e-06, -3.02750114e-01, -3.99194273e+01],\n",
       "       [-1.07061874e-08,  2.97210657e-07,  5.83516071e-06,\n",
       "         2.90948007e-05, -5.76529157e-02,  2.80914444e-04],\n",
       "       [ 9.25224685e-06, -2.64182649e-04, -3.02750114e-01,\n",
       "        -5.76529157e-02,  1.52290467e+02,  5.93492996e-01],\n",
       "       [-4.44139248e-01,  1.16640543e+01, -3.99194273e+01,\n",
       "         2.80914444e-04,  5.93492996e-01,  8.75354767e+04]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 5351.342789654394\n",
      "MAPE: 228.69943966435477%\n",
      "Numero di valutazioni della funzione: 1895\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Funzione di errore con regolarizzazione\n",
    "def loss(params, x, y, lambda_reg):\n",
    "    A, B, C, D, E, F = params\n",
    "    y_pred = A * x**B + C * np.sin(D * x + E) + F\n",
    "    mse = np.mean((y - y_pred)**2)\n",
    "    reg = lambda_reg * (F**2)  # Penalizzazione\n",
    "    return mse + reg\n",
    "\n",
    "# Ottimizzazione\n",
    "initial_params = [1, 1, 1, 1, 1, 1]\n",
    "result = minimize(loss, initial_params, args=(x, y, 0.01))  # lambda_reg=0.01\n",
    "\n",
    "# Parametri ottimizzati\n",
    "optimized_params = result.x\n",
    "A, B, C, D, E, F = optimized_params\n",
    "\n",
    "# Calcolo dei valori predetti\n",
    "y_pred = A * x**B + C * np.sin(D * x + E) + F\n",
    "\n",
    "# Calcolo MAE\n",
    "mae = mean_absolute_error(y, y_pred)\n",
    "\n",
    "# Calcolo MAPE\n",
    "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
    "\n",
    "# Numero di valutazioni della funzione\n",
    "n_evaluations = result.nfev\n",
    "\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"MAPE: {mape}%\")\n",
    "print(f\"Numero di valutazioni della funzione: {n_evaluations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.22160214e-03,  1.93841250e+00, -2.32314951e+01,  7.89011201e-01,\n",
       "        4.36347449e+02, -1.71359330e+03])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: Desired error not necessarily achieved due to precision loss.\n",
       "  success: False\n",
       "   status: 2\n",
       "      fun: 65181055.29958218\n",
       "        x: [ 4.222e-03  1.938e+00 -2.323e+01  7.890e-01  4.363e+02\n",
       "            -1.714e+03]\n",
       "      nit: 169\n",
       "      jac: [-2.059e+05 -1.098e+04  5.000e-01 -4.233e+04 -7.000e+00\n",
       "            -1.500e+00]\n",
       " hess_inv: [[ 3.658e-11 -1.072e-09 ...  5.480e-07  9.438e-08]\n",
       "            [-1.072e-09  3.145e-08 ... -1.607e-05 -2.796e-06]\n",
       "            ...\n",
       "            [ 5.480e-07 -1.607e-05 ...  1.934e-02 -2.021e-03]\n",
       "            [ 9.438e-08 -2.796e-06 ... -2.021e-03  5.910e-03]]\n",
       "     nfev: 1895\n",
       "     njev: 269"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reti neurali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per creare e compilare il modello\n",
    "def create_model(input_shape, width, depth, activation, loss):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=(input_shape,)))\n",
    "    for _ in range(depth):\n",
    "        model.add(tf.keras.layers.Dense(width, activation=activation))\n",
    "    model.add(tf.keras.layers.Dense(1))  # Uscita singola per la previsione del prezzo\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(), loss=loss)\n",
    "    return model\n",
    "\n",
    "# Funzione per dividere i dati in train, validation e test\n",
    "def split_data(x, y, train_size=0.7, val_size=0.15, test_size=0.15):\n",
    "    x_train, x_temp, y_train, y_temp = train_test_split(x, y, train_size=train_size, random_state=42, shuffle=False)\n",
    "    val_ratio = val_size / (val_size + test_size)\n",
    "    x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, train_size=val_ratio, random_state=42, shuffle=False)\n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test\n",
    "\n",
    "# Funzione per allenare il modello\n",
    "def train_model(model, x_train, y_train, x_val, y_val, patience=10, epochs=100, batch_size=32):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=patience, restore_best_weights=True\n",
    "    )\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        epochs=epochs,\n",
    "        callbacks=[early_stopping],\n",
    "        batch_size=batch_size,\n",
    "        verbose=2\n",
    "    )\n",
    "    return history\n",
    "\n",
    "# Funzione per valutare il modello\n",
    "def evaluate_model(model, x, y):\n",
    "    y_pred = model.predict(x).flatten()\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
    "    return mae, mape\n",
    "\n",
    "# Funzione principale\n",
    "def main(data, train_size=0.7, val_size=0.15, test_size=0.15, width=64, depth=3, patience=10, epochs=100, batch_size=32, activation='relu', loss='mse'):\n",
    "    # Prepara i dati\n",
    "    x = np.arange(1, len(data) + 1).reshape(-1, 1)  # Indici come input\n",
    "    y = data['Price (€)'].values  # Prezzi come target\n",
    "\n",
    "    x_train, x_val, x_test, y_train, y_val, y_test = split_data(x, y, train_size, val_size, test_size)\n",
    "\n",
    "    # Crea il modello\n",
    "    model = create_model(input_shape=x_train.shape[1], width=width, depth=depth, activation=activation, loss=loss)\n",
    "\n",
    "    # Allena il modello\n",
    "    print(\"Training the model...\")\n",
    "    train_model(model, x_train, y_train, x_val, y_val, patience=patience, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    # Valuta il modello\n",
    "    print(\"Evaluating the model...\")\n",
    "    train_mae, train_mape = evaluate_model(model, x_train, y_train)\n",
    "    val_mae, val_mape = evaluate_model(model, x_val, y_val)\n",
    "    test_mae, test_mape = evaluate_model(model, x_test, y_test)\n",
    "\n",
    "    # Risultati\n",
    "    print(f\"Train MAE: {train_mae}, Train MAPE: {train_mape}%\")\n",
    "    print(f\"Validation MAE: {val_mae}, Validation MAPE: {val_mape}%\")\n",
    "    print(f\"Test MAE: {test_mae}, Test MAPE: {test_mape}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alessandro\\Desktop\\Cartelle\\Mie\\Programmi personali in Python\\Kaggle\\Bitcoin Historical Dataset\\trading_env\\lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 - 7s - 77ms/step - loss: 90.4672 - val_loss: 99.7955\n",
      "Epoch 2/1000\n",
      "87/87 - 4s - 42ms/step - loss: 82.5879 - val_loss: 99.6999\n",
      "Epoch 3/1000\n",
      "87/87 - 4s - 42ms/step - loss: 80.3860 - val_loss: 99.6371\n",
      "Epoch 4/1000\n",
      "87/87 - 4s - 44ms/step - loss: 79.0749 - val_loss: 99.5741\n",
      "Epoch 5/1000\n",
      "87/87 - 4s - 42ms/step - loss: 77.8595 - val_loss: 99.5124\n",
      "Epoch 6/1000\n",
      "87/87 - 4s - 42ms/step - loss: 76.6565 - val_loss: 99.4464\n",
      "Epoch 7/1000\n",
      "87/87 - 4s - 42ms/step - loss: 75.5384 - val_loss: 99.3850\n",
      "Epoch 8/1000\n",
      "87/87 - 4s - 42ms/step - loss: 75.0042 - val_loss: 99.3608\n",
      "Epoch 9/1000\n",
      "87/87 - 4s - 43ms/step - loss: 74.9422 - val_loss: 99.3561\n",
      "Epoch 10/1000\n",
      "87/87 - 4s - 42ms/step - loss: 74.9517 - val_loss: 99.3505\n",
      "Epoch 11/1000\n",
      "87/87 - 4s - 43ms/step - loss: 74.9343 - val_loss: 99.3508\n",
      "Epoch 12/1000\n",
      "87/87 - 4s - 43ms/step - loss: 74.9412 - val_loss: 99.3487\n",
      "Epoch 13/1000\n",
      "87/87 - 4s - 42ms/step - loss: 74.9367 - val_loss: 99.3520\n",
      "Epoch 14/1000\n",
      "87/87 - 4s - 44ms/step - loss: 74.9455 - val_loss: 99.3483\n",
      "Epoch 15/1000\n",
      "87/87 - 4s - 44ms/step - loss: 74.9417 - val_loss: 99.3513\n",
      "Epoch 16/1000\n",
      "87/87 - 4s - 43ms/step - loss: 74.9345 - val_loss: 99.3516\n",
      "Epoch 17/1000\n",
      "87/87 - 4s - 43ms/step - loss: 74.9372 - val_loss: 99.3537\n",
      "Epoch 18/1000\n",
      "87/87 - 4s - 45ms/step - loss: 74.9353 - val_loss: 99.3464\n",
      "Epoch 19/1000\n",
      "87/87 - 4s - 45ms/step - loss: 74.9344 - val_loss: 99.3513\n",
      "Epoch 20/1000\n",
      "87/87 - 4s - 45ms/step - loss: 74.9441 - val_loss: 99.3471\n",
      "Epoch 21/1000\n",
      "87/87 - 4s - 43ms/step - loss: 74.9454 - val_loss: 99.3481\n",
      "Epoch 22/1000\n",
      "87/87 - 4s - 42ms/step - loss: 74.9340 - val_loss: 99.3486\n",
      "Epoch 23/1000\n",
      "87/87 - 4s - 43ms/step - loss: 74.9411 - val_loss: 99.3546\n",
      "Epoch 24/1000\n",
      "87/87 - 4s - 43ms/step - loss: 74.9381 - val_loss: 99.3511\n",
      "Epoch 25/1000\n",
      "87/87 - 4s - 44ms/step - loss: 74.9325 - val_loss: 99.3483\n",
      "Epoch 26/1000\n",
      "87/87 - 4s - 43ms/step - loss: 74.9375 - val_loss: 99.3480\n",
      "Epoch 27/1000\n",
      "87/87 - 4s - 43ms/step - loss: 74.9382 - val_loss: 99.3442\n",
      "Epoch 28/1000\n",
      "87/87 - 4s - 43ms/step - loss: 74.9339 - val_loss: 99.3491\n",
      "Epoch 29/1000\n",
      "87/87 - 4s - 44ms/step - loss: 74.9360 - val_loss: 99.3509\n",
      "Epoch 30/1000\n",
      "87/87 - 4s - 45ms/step - loss: 74.9391 - val_loss: 99.3541\n",
      "Epoch 31/1000\n",
      "87/87 - 4s - 45ms/step - loss: 74.9344 - val_loss: 99.3516\n",
      "Epoch 32/1000\n",
      "87/87 - 4s - 46ms/step - loss: 74.9391 - val_loss: 99.3516\n",
      "Epoch 33/1000\n",
      "87/87 - 4s - 47ms/step - loss: 74.9400 - val_loss: 99.3504\n",
      "Epoch 34/1000\n",
      "87/87 - 4s - 46ms/step - loss: 74.9394 - val_loss: 99.3557\n",
      "Epoch 35/1000\n",
      "87/87 - 4s - 45ms/step - loss: 74.9467 - val_loss: 99.3549\n",
      "Epoch 36/1000\n",
      "87/87 - 4s - 47ms/step - loss: 74.9458 - val_loss: 99.3505\n",
      "Epoch 37/1000\n",
      "87/87 - 4s - 44ms/step - loss: 74.9388 - val_loss: 99.3430\n",
      "Epoch 38/1000\n",
      "87/87 - 4s - 43ms/step - loss: 74.9410 - val_loss: 99.3490\n",
      "Epoch 39/1000\n",
      "87/87 - 4s - 44ms/step - loss: 74.9320 - val_loss: 99.3505\n",
      "Epoch 40/1000\n",
      "87/87 - 4s - 43ms/step - loss: 74.9384 - val_loss: 99.3504\n",
      "Epoch 41/1000\n",
      "87/87 - 4s - 48ms/step - loss: 74.9338 - val_loss: 99.3515\n",
      "Epoch 42/1000\n",
      "87/87 - 4s - 48ms/step - loss: 74.9369 - val_loss: 99.3497\n",
      "Epoch 43/1000\n",
      "87/87 - 4s - 46ms/step - loss: 74.9410 - val_loss: 99.3509\n",
      "Epoch 44/1000\n",
      "87/87 - 4s - 45ms/step - loss: 74.9339 - val_loss: 99.3466\n",
      "Epoch 45/1000\n",
      "87/87 - 4s - 48ms/step - loss: 74.9493 - val_loss: 99.3494\n",
      "Epoch 46/1000\n",
      "87/87 - 5s - 61ms/step - loss: 74.9428 - val_loss: 99.3468\n",
      "Epoch 47/1000\n",
      "87/87 - 5s - 54ms/step - loss: 74.9371 - val_loss: 99.3494\n",
      "Evaluating the model...\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Train MAE: 3204.443576438403, Train MAPE: 74.93280401841463%\n",
      "Validation MAE: 36281.20323936847, Validation MAPE: 99.34295446442195%\n",
      "Test MAE: 26147.413698425564, Test MAPE: 99.09567078807578%\n"
     ]
    }
   ],
   "source": [
    "main(dati, train_size=0.7, val_size=0.15, test_size=0.15, width=1024, depth=5, patience=10, epochs=1000, batch_size=32, activation='sigmoid', loss='mape')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
