{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Price (€)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-04-28 00:00:00.000</td>\n",
       "      <td>103.186200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-04-29 00:00:00.000</td>\n",
       "      <td>110.374500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-04-30 00:00:00.000</td>\n",
       "      <td>106.312800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-05-01 00:00:00.000</td>\n",
       "      <td>88.629100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-05-02 00:00:00.000</td>\n",
       "      <td>80.592300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3957</th>\n",
       "      <td>2024-02-29 00:00:00.000</td>\n",
       "      <td>57717.736389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>2024-03-01 00:00:00.000</td>\n",
       "      <td>56734.564616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3959</th>\n",
       "      <td>2024-03-02 00:00:00.000</td>\n",
       "      <td>57560.483900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3960</th>\n",
       "      <td>2024-03-03 00:00:00.000</td>\n",
       "      <td>57229.676585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3961</th>\n",
       "      <td>2024-03-04 00:00:00.000</td>\n",
       "      <td>58157.094855</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Timestamp     Price (€)\n",
       "0     2013-04-28 00:00:00.000    103.186200\n",
       "1     2013-04-29 00:00:00.000    110.374500\n",
       "2     2013-04-30 00:00:00.000    106.312800\n",
       "3     2013-05-01 00:00:00.000     88.629100\n",
       "4     2013-05-02 00:00:00.000     80.592300\n",
       "...                       ...           ...\n",
       "3957  2024-02-29 00:00:00.000  57717.736389\n",
       "3958  2024-03-01 00:00:00.000  56734.564616\n",
       "3959  2024-03-02 00:00:00.000  57560.483900\n",
       "3960  2024-03-03 00:00:00.000  57229.676585\n",
       "3961  2024-03-04 00:00:00.000  58157.094855\n",
       "\n",
       "[3962 rows x 2 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dati = pd.read_csv('bitcoin_data_28-4-2013_4-3-2024_granularità_1_giorno.csv')\n",
    "dati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri ottimizzati: [ 4.54751661e-03  1.92959282e+00  2.94437752e+01  9.97093830e-01\n",
      " -1.27923201e+01 -1.78820149e+03]\n",
      "MAE: 5359.841786647315\n",
      "MAPE: 234.73707941722188%\n",
      "Numero di valutazioni della funzione: 324\n"
     ]
    }
   ],
   "source": [
    "# Contatore globale\n",
    "eval_count = 0\n",
    "\n",
    "# Legge da fittare: y = A * x^B\n",
    "def legge(x, A, B, C, D, E, F):\n",
    "    global eval_count\n",
    "    eval_count += 1\n",
    "    return A * x**B + C * np.sin(D*x + E) + F\n",
    "\n",
    "# Creiamo un array per l'asse x (tempo o indice dei prezzi)\n",
    "x = np.arange(1, len(dati) + 1)\n",
    "y = dati['Price (€)'].values\n",
    "\n",
    "# Ottimizzazione dei parametri\n",
    "try:\n",
    "    # curve_fit cerca i migliori parametri A e B\n",
    "    popt, pcov = curve_fit(legge, x, y, p0=[1, 1, 1, 1, 1, 0], maxfev=10000)\n",
    "\n",
    "    # Generazione dei valori predetti\n",
    "    y_pred = legge(x, *popt)\n",
    "\n",
    "    # Calcolo degli errori\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
    "\n",
    "    print(f\"Parametri ottimizzati: {popt}\")\n",
    "    print(f\"MAE: {mae}\")\n",
    "    print(f\"MAPE: {mape}%\")\n",
    "    print(f\"Numero di valutazioni della funzione: {eval_count}\")\n",
    "\n",
    "except RuntimeError as e:\n",
    "    print(\"Errore nell'ottimizzazione:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.85425086e-06, -1.02818258e-04,  1.65466477e-04,\n",
       "        -1.07061874e-08,  9.25224685e-06, -4.44139248e-01],\n",
       "       [-1.02818258e-04,  2.74454381e-03, -4.28154896e-03,\n",
       "         2.97210657e-07, -2.64182649e-04,  1.16640543e+01],\n",
       "       [ 1.65466477e-04, -4.28154896e-03,  3.29326561e+04,\n",
       "         5.83516071e-06, -3.02750114e-01, -3.99194273e+01],\n",
       "       [-1.07061874e-08,  2.97210657e-07,  5.83516071e-06,\n",
       "         2.90948007e-05, -5.76529157e-02,  2.80914444e-04],\n",
       "       [ 9.25224685e-06, -2.64182649e-04, -3.02750114e-01,\n",
       "        -5.76529157e-02,  1.52290467e+02,  5.93492996e-01],\n",
       "       [-4.44139248e-01,  1.16640543e+01, -3.99194273e+01,\n",
       "         2.80914444e-04,  5.93492996e-01,  8.75354767e+04]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 5351.342789654394\n",
      "MAPE: 228.69943966435477%\n",
      "Numero di valutazioni della funzione: 1895\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Funzione di errore con regolarizzazione\n",
    "def loss(params, x, y, lambda_reg):\n",
    "    A, B, C, D, E, F = params\n",
    "    y_pred = A * x**B + C * np.sin(D * x + E) + F\n",
    "    mse = np.mean((y - y_pred)**2)\n",
    "    reg = lambda_reg * (F**2)  # Penalizzazione\n",
    "    return mse + reg\n",
    "\n",
    "# Ottimizzazione\n",
    "initial_params = [1, 1, 1, 1, 1, 1]\n",
    "result = minimize(loss, initial_params, args=(x, y, 0.01))  # lambda_reg=0.01\n",
    "\n",
    "# Parametri ottimizzati\n",
    "optimized_params = result.x\n",
    "A, B, C, D, E, F = optimized_params\n",
    "\n",
    "# Calcolo dei valori predetti\n",
    "y_pred = A * x**B + C * np.sin(D * x + E) + F\n",
    "\n",
    "# Calcolo MAE\n",
    "mae = mean_absolute_error(y, y_pred)\n",
    "\n",
    "# Calcolo MAPE\n",
    "mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
    "\n",
    "# Numero di valutazioni della funzione\n",
    "n_evaluations = result.nfev\n",
    "\n",
    "print(f\"MAE: {mae}\")\n",
    "print(f\"MAPE: {mape}%\")\n",
    "print(f\"Numero di valutazioni della funzione: {n_evaluations}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.22160214e-03,  1.93841250e+00, -2.32314951e+01,  7.89011201e-01,\n",
       "        4.36347449e+02, -1.71359330e+03])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  message: Desired error not necessarily achieved due to precision loss.\n",
       "  success: False\n",
       "   status: 2\n",
       "      fun: 65181055.29958218\n",
       "        x: [ 4.222e-03  1.938e+00 -2.323e+01  7.890e-01  4.363e+02\n",
       "            -1.714e+03]\n",
       "      nit: 169\n",
       "      jac: [-2.059e+05 -1.098e+04  5.000e-01 -4.233e+04 -7.000e+00\n",
       "            -1.500e+00]\n",
       " hess_inv: [[ 3.658e-11 -1.072e-09 ...  5.480e-07  9.438e-08]\n",
       "            [-1.072e-09  3.145e-08 ... -1.607e-05 -2.796e-06]\n",
       "            ...\n",
       "            [ 5.480e-07 -1.607e-05 ...  1.934e-02 -2.021e-03]\n",
       "            [ 9.438e-08 -2.796e-06 ... -2.021e-03  5.910e-03]]\n",
       "     nfev: 1895\n",
       "     njev: 269"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reti neurali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per creare e compilare il modello\n",
    "def create_model(input_shape, width, depth):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=(input_shape,)))\n",
    "    for _ in range(depth):\n",
    "        model.add(tf.keras.layers.Dense(width, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))  # Uscita singola per la previsione del prezzo\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(), loss='mse')\n",
    "    return model\n",
    "\n",
    "# Funzione per dividere i dati in train, validation e test\n",
    "def split_data(x, y, train_size=0.7, val_size=0.15, test_size=0.15):\n",
    "    x_train, x_temp, y_train, y_temp = train_test_split(x, y, train_size=train_size, random_state=42, shuffle=False)\n",
    "    val_ratio = val_size / (val_size + test_size)\n",
    "    x_val, x_test, y_val, y_test = train_test_split(x_temp, y_temp, train_size=val_ratio, random_state=42, shuffle=False)\n",
    "    return x_train, x_val, x_test, y_train, y_val, y_test\n",
    "\n",
    "# Funzione per allenare il modello\n",
    "def train_model(model, x_train, y_train, x_val, y_val, patience=10, epochs=100):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss', patience=patience, restore_best_weights=True\n",
    "    )\n",
    "    history = model.fit(\n",
    "        x_train, y_train,\n",
    "        validation_data=(x_val, y_val),\n",
    "        epochs=epochs,\n",
    "        callbacks=[early_stopping],\n",
    "        batch_size=32,\n",
    "        verbose=2\n",
    "    )\n",
    "    return history\n",
    "\n",
    "# Funzione per valutare il modello\n",
    "def evaluate_model(model, x, y):\n",
    "    y_pred = model.predict(x).flatten()\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    mape = np.mean(np.abs((y - y_pred) / y)) * 100\n",
    "    return mae, mape\n",
    "\n",
    "# Funzione principale\n",
    "def main(data, train_size=0.7, val_size=0.15, test_size=0.15, width=64, depth=3, patience=10):\n",
    "    # Prepara i dati\n",
    "    x = np.arange(1, len(data) + 1).reshape(-1, 1)  # Indici come input\n",
    "    y = data['Price (€)'].values  # Prezzi come target\n",
    "\n",
    "    x_train, x_val, x_test, y_train, y_val, y_test = split_data(x, y, train_size, val_size, test_size)\n",
    "\n",
    "    # Crea il modello\n",
    "    model = create_model(input_shape=x_train.shape[1], width=width, depth=depth)\n",
    "\n",
    "    # Allena il modello\n",
    "    print(\"Training the model...\")\n",
    "    train_model(model, x_train, y_train, x_val, y_val, patience=patience)\n",
    "\n",
    "    # Valuta il modello\n",
    "    print(\"Evaluating the model...\")\n",
    "    train_mae, train_mape = evaluate_model(model, x_train, y_train)\n",
    "    val_mae, val_mape = evaluate_model(model, x_val, y_val)\n",
    "    test_mae, test_mape = evaluate_model(model, x_test, y_test)\n",
    "\n",
    "    # Risultati\n",
    "    print(f\"Train MAE: {train_mae}, Train MAPE: {train_mape}%\")\n",
    "    print(f\"Validation MAE: {val_mae}, Validation MAPE: {val_mape}%\")\n",
    "    print(f\"Test MAE: {test_mae}, Test MAPE: {test_mape}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alessandro\\Desktop\\Cartelle\\Mie\\Programmi personali in Python\\Kaggle\\Bitcoin Historical Dataset\\trading_env\\lib\\site-packages\\keras\\src\\layers\\core\\input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch 1/100\n",
      "87/87 - 9s - 104ms/step - loss: 6576272.0000 - val_loss: 900428416.0000\n",
      "Epoch 2/100\n",
      "87/87 - 4s - 50ms/step - loss: 5832108.5000 - val_loss: 883362560.0000\n",
      "Epoch 3/100\n",
      "87/87 - 4s - 48ms/step - loss: 5981157.0000 - val_loss: 837452224.0000\n",
      "Epoch 4/100\n",
      "87/87 - 4s - 49ms/step - loss: 5673934.5000 - val_loss: 802561664.0000\n",
      "Epoch 5/100\n",
      "87/87 - 5s - 53ms/step - loss: 5412712.0000 - val_loss: 897176896.0000\n",
      "Epoch 6/100\n",
      "87/87 - 4s - 48ms/step - loss: 5552547.5000 - val_loss: 895198208.0000\n",
      "Epoch 7/100\n",
      "87/87 - 4s - 48ms/step - loss: 5539336.0000 - val_loss: 990580160.0000\n",
      "Epoch 8/100\n",
      "87/87 - 4s - 51ms/step - loss: 5540361.5000 - val_loss: 818008256.0000\n",
      "Epoch 9/100\n",
      "87/87 - 5s - 56ms/step - loss: 5479924.0000 - val_loss: 823082304.0000\n",
      "Epoch 10/100\n",
      "87/87 - 5s - 53ms/step - loss: 5408308.5000 - val_loss: 854647680.0000\n",
      "Epoch 11/100\n",
      "87/87 - 4s - 50ms/step - loss: 5437363.5000 - val_loss: 858564096.0000\n",
      "Epoch 12/100\n",
      "87/87 - 5s - 57ms/step - loss: 5370140.5000 - val_loss: 883264448.0000\n",
      "Epoch 13/100\n",
      "87/87 - 5s - 57ms/step - loss: 5304220.5000 - val_loss: 827083904.0000\n",
      "Epoch 14/100\n",
      "87/87 - 5s - 56ms/step - loss: 5373547.5000 - val_loss: 796149632.0000\n",
      "Epoch 15/100\n",
      "87/87 - 5s - 57ms/step - loss: 5310256.5000 - val_loss: 810856768.0000\n",
      "Epoch 16/100\n",
      "87/87 - 5s - 60ms/step - loss: 5295771.5000 - val_loss: 947239488.0000\n",
      "Epoch 17/100\n",
      "87/87 - 5s - 58ms/step - loss: 5278650.5000 - val_loss: 816840320.0000\n",
      "Epoch 18/100\n",
      "87/87 - 5s - 57ms/step - loss: 5230477.0000 - val_loss: 918689344.0000\n",
      "Epoch 19/100\n",
      "87/87 - 6s - 66ms/step - loss: 5207121.0000 - val_loss: 927422016.0000\n",
      "Epoch 20/100\n",
      "87/87 - 5s - 58ms/step - loss: 5333113.0000 - val_loss: 904228096.0000\n",
      "Epoch 21/100\n",
      "87/87 - 5s - 56ms/step - loss: 5369740.5000 - val_loss: 917211712.0000\n",
      "Epoch 22/100\n",
      "87/87 - 5s - 63ms/step - loss: 5249242.0000 - val_loss: 869854400.0000\n",
      "Epoch 23/100\n",
      "87/87 - 5s - 56ms/step - loss: 4996108.0000 - val_loss: 814614656.0000\n",
      "Epoch 24/100\n",
      "87/87 - 5s - 58ms/step - loss: 4967030.5000 - val_loss: 857041536.0000\n",
      "Evaluating the model...\n",
      "\u001b[1m87/87\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step\n",
      "\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "Train MAE: 1859.9669915657366, Train MAPE: 289.961474904129%\n",
      "Validation MAE: 26454.87243930238, Validation MAPE: 69.97143341324042%\n",
      "Test MAE: 14351.2069926622, Test MAPE: 51.0660505419028%\n"
     ]
    }
   ],
   "source": [
    "main(dati, train_size=0.7, val_size=0.15, test_size=0.15, width=1024, depth=5, patience=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
